{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:54:04.912323Z","iopub.execute_input":"2025-02-28T05:54:04.912611Z","iopub.status.idle":"2025-02-28T05:54:16.617820Z","shell.execute_reply.started":"2025-02-28T05:54:04.912587Z","shell.execute_reply":"2025-02-28T05:54:16.616885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'\ntest_path = '/kaggle/input/histopathologic-cancer-detection/test.csv'\nsample_path = '/kaggle/input/histopathologic-cancer-detection/sample_submission.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:54:20.089011Z","iopub.execute_input":"2025-02-28T05:54:20.089518Z","iopub.status.idle":"2025-02-28T05:54:20.093106Z","shell.execute_reply.started":"2025-02-28T05:54:20.089494Z","shell.execute_reply":"2025-02-28T05:54:20.092289Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA ","metadata":{}},{"cell_type":"markdown","source":"## 1. Load and Check the first 5 images","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport pandas as pd\n\n# Load labels\nlabels_df = pd.read_csv(\"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\")\n\n# Get the first five image IDs\nfirst_five_ids = labels_df[\"id\"].head(5).tolist()\n\n# Load and display the first five images\nfig, axes = plt.subplots(1, 5, figsize=(15, 5))\n\nfor i, image_id in enumerate(first_five_ids):\n    image_path = f\"/kaggle/input/histopathologic-cancer-detection/train/{image_id}.tif\"\n    \n    # Load image\n    image = cv2.imread(image_path)\n    if image is not None:\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct display\n\n        # Display image\n        axes[i].imshow(image)\n        axes[i].axis(\"off\")  # Hide axes\n        axes[i].set_title(image_id[:6])  # Shortened ID for readability\n    else:\n        axes[i].text(0.5, 0.5, \"Image Not Found\", ha='center', va='center', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:54:25.791091Z","iopub.execute_input":"2025-02-28T05:54:25.791371Z","iopub.status.idle":"2025-02-28T05:54:26.822108Z","shell.execute_reply.started":"2025-02-28T05:54:25.791351Z","shell.execute_reply":"2025-02-28T05:54:26.821011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define the path to images\nimage_dir = '/kaggle/input/histopathologic-cancer-detection/train/'\n\n# Get the first 5 image IDs\nfirst_five_ids = labels_df['id'].head(5).tolist()\n\n# Check pixel value ranges for the first 5 images\npixel_stats = []  # Use a list instead of a dictionary\n\nfor image_id in first_five_ids:\n    image_path = f\"{image_dir}{image_id}.tif\"\n    image = cv2.imread(image_path)\n\n    if image is not None:\n        pixel_stats.append({\n            \"Image ID\": image_id,\n            \"Min Pixel Value\": int(image.min()),\n            \"Max Pixel Value\": int(image.max()),\n            \"Mean Pixel Value\": float(image.mean())\n        })\n    else:\n        pixel_stats.append({\"Image ID\": image_id, \"Error\": \"Image not found\"})\n\n# Convert to a DataFrame for better display\npixel_stats_df = pd.DataFrame(pixel_stats)\n\n# Display the result\nprint(pixel_stats_df)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:54:31.617749Z","iopub.execute_input":"2025-02-28T05:54:31.618120Z","iopub.status.idle":"2025-02-28T05:54:31.642173Z","shell.execute_reply.started":"2025-02-28T05:54:31.618094Z","shell.execute_reply":"2025-02-28T05:54:31.641310Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- The pixels range from 0 to 255, this means the images are not normalized. I will need to normalize the images by dividing by 255 before feeding them into a CNN.\n- The images have wide range of brightness. \n\n","metadata":{}},{"cell_type":"markdown","source":"## 2. Understand the Label Distribution","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.countplot(x='label', data=labels_df)\nplt.title(\"Distribution of Labels (No Tumor vs Tumor)\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:56:46.203678Z","iopub.execute_input":"2025-02-28T05:56:46.203983Z","iopub.status.idle":"2025-02-28T05:56:46.353404Z","shell.execute_reply.started":"2025-02-28T05:56:46.203959Z","shell.execute_reply":"2025-02-28T05:56:46.352545Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- The count of images with No Tumor (label 0) is significantly larger than the count of images with Tumor (label 1).\n- This suggests that the dataset is imbalanced, with more images that don't contain tumor tissue compared to those that do. This imbalance could be a concern when training models, as the model may become biased towards predicting the majority class.","metadata":{}},{"cell_type":"markdown","source":"## 3. Image Shape and Size","metadata":{}},{"cell_type":"code","source":"# Load one sample image to check its dimensions\nsample_image_path = f\"/kaggle/input/histopathologic-cancer-detection/train/{labels_df['id'][0]}.tif\"\nsample_image = cv2.imread(sample_image_path)\nprint(f\"Image shape: {sample_image.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T03:26:45.367950Z","iopub.execute_input":"2025-02-28T03:26:45.368531Z","iopub.status.idle":"2025-02-28T03:26:45.374093Z","shell.execute_reply.started":"2025-02-28T03:26:45.368501Z","shell.execute_reply":"2025-02-28T03:26:45.373404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The image shape of (96, 96, 3) indicates that the images are of size 96x96 pixels with 3 color channels (RGB). ","metadata":{}},{"cell_type":"markdown","source":"# CNN Model Training ","metadata":{}},{"cell_type":"markdown","source":"## 1. Build CNN","metadata":{}},{"cell_type":"code","source":"# Build a simple CNN model\nmodel = Sequential()\n\n# Convolutional layer + Max pooling layer\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(96, 96, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Another convolutional + max pooling layer\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Flatten the output of the convolutional layers\nmodel.add(Flatten())\n\n# Dense layer with dropout for regularization\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Output layer with 1 neuron for binary classification\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:11:04.507503Z","iopub.execute_input":"2025-02-28T07:11:04.507819Z","iopub.status.idle":"2025-02-28T07:11:04.572079Z","shell.execute_reply.started":"2025-02-28T07:11:04.507796Z","shell.execute_reply":"2025-02-28T07:11:04.571224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Train the model","metadata":{}},{"cell_type":"code","source":"# experimental \nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define paths\ndata_dir = \"/kaggle/input/histopathologic-cancer-detection/train\"  # Path to images\ncsv_path = \"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\"  # Path to CSV file\n\n# Load CSV file\ndf = pd.read_csv(csv_path)\n\n# Convert column names to match ImageDataGenerator requirements\ndf.columns = [\"id\", \"label\"]  # Ensure column names are correct\n\n# Convert label column to string (needed for `class_mode='binary'`)\ndf[\"label\"] = df[\"label\"].astype(str)\n\n# Add '.tif' extension to filenames\ndf[\"id\"] = df[\"id\"].astype(str) + \".tif\"\n\n# Select a small subset \n#df_subset = df.sample(n=20000, random_state=42)  # Use a smaller dataset for faster testing\ndf_subset = df \n\n# Define ImageDataGenerator with 80-20 split\ndatagen = ImageDataGenerator(rescale=1.0 / 255, \n                             validation_split=0.2,\n                            )\n\n# Training generator (80%)\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=df_subset,\n    directory=data_dir,  # Folder containing all images\n    x_col=\"id\",  # Column name for image filenames\n    y_col=\"label\",  # Column name for binary labels\n    target_size=(96, 96),  # Resize images if needed\n    batch_size=32,  \n    class_mode=\"binary\",  # Binary classification (0 or 1)\n    subset=\"training\",  # Use training split\n    shuffle=True\n)\n\n# Validation generator (20%)\nval_generator = datagen.flow_from_dataframe(\n    dataframe=df_subset,\n    directory=data_dir,\n    x_col=\"id\",\n    y_col=\"label\",\n    target_size=(96, 96),\n    batch_size=32,\n    class_mode=\"binary\",\n    subset=\"validation\",  # Use validation split\n    shuffle=True\n)\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=10\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:35:49.279863Z","iopub.execute_input":"2025-02-28T07:35:49.280195Z","iopub.status.idle":"2025-02-28T09:07:23.471314Z","shell.execute_reply.started":"2025-02-28T07:35:49.280174Z","shell.execute_reply":"2025-02-28T09:07:23.470615Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Visualize Training History","metadata":{}},{"cell_type":"code","source":"# Plot training & validation accuracy and loss\nplt.figure(figsize=(12, 4))\n\n# Accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.ylim(0,1)\n\n# Loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Loss')\nplt.legend()\nplt.ylim(0,1)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:07:55.255236Z","iopub.execute_input":"2025-02-28T09:07:55.255547Z","iopub.status.idle":"2025-02-28T09:07:55.617750Z","shell.execute_reply.started":"2025-02-28T09:07:55.255522Z","shell.execute_reply":"2025-02-28T09:07:55.616916Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# Make Predictions","metadata":{}},{"cell_type":"code","source":"# Make predictions on the test set (replace 'test_images' with the actual test data)\ntest_images = np.array([load_and_preprocess_image(image_id) for image_id in test_image_ids][])\npredictions = model.predict(test_images)\n\n# If you need binary predictions (0 or 1)\nbinary_predictions = (predictions > 0.5).astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:20:38.314083Z","iopub.status.idle":"2025-02-27T09:20:38.314521Z","shell.execute_reply":"2025-02-27T09:20:38.314331Z"}},"outputs":[],"execution_count":null}]}